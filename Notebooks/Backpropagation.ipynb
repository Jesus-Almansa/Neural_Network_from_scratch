{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "\n",
    "1. [Imports](#imports)\n",
    "2. [Parabolic Function - Derivative example](#parabolic-function---derivative-example)\n",
    "3. [Forward Pass Manually](#forward-pass-manually)\n",
    "4. [First Manual backpropagation](#first-manual-backpropagation)\n",
    "5. [Hiperbolic tangent definition](#hiperbolic-tangent-definition)\n",
    "6. [Second Manual backpropagation](#second-manual-backpropagation)\n",
    "    - [Initialize values of the network](#initialize-values-of-the-network)\n",
    "    - [Backpropagation](#backpropagation)\n",
    "7. [Semiautomation of the backpropagation](#semiautomation-of-the-backpropagation)\n",
    "    - [Reset values of the network](#reset-values-of-the-network)\n",
    "8. [Topological graph](#topological-graph)\n",
    "    - [Explanation](#explanation)\n",
    "9. [Automation of the backpropagation](#automation-of-the-backpropagation)\n",
    "10. [New topologies - Autonomous Backpropagation](#new-topologies---Autonomous-Backpropagation)\n",
    "11. [Pytorch approach](#pytorch-approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.backpropagation import *\n",
    "from src.graph_nn import *\n",
    "from src.nn import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parabolic Function - Derivative example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.arange(-5,5,0.25)\n",
    "ys = f(xs)\n",
    "plt.plot(xs,ys)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.0000001\n",
    "x = -3.0\n",
    "(f(x+h) - f(x))/h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Pass Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get more complex\n",
    "a = 2.0\n",
    "b = -3.0\n",
    "c = 10.0\n",
    "d = a*b + c\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.0000001\n",
    "\n",
    "a = 2.0\n",
    "b = -3.0\n",
    "c = 10.0\n",
    "\n",
    "\n",
    "d1 = a*b + c\n",
    "a += h\n",
    "d2 = a*b + c\n",
    "\n",
    "print('d1',d1)\n",
    "print('d2',d2)\n",
    "print('slope',(d2-d1)/h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.0000001\n",
    "\n",
    "a = 2.0\n",
    "b = -3.0\n",
    "c = 10.0\n",
    "\n",
    "\n",
    "d1 = a*b + c\n",
    "b += h\n",
    "d2 = a*b + c\n",
    "\n",
    "print('d1',d1)\n",
    "print('d2',d2)\n",
    "print('slope',(d2-d1)/h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = a*b+c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Value(2.0, label='a')\n",
    "b = Value(-3.0, label='b')\n",
    "c = Value(10.0, label='c')\n",
    "e = a*b; e.label = 'e'\n",
    "d = e + c; d.label = 'd'\n",
    "f = Value(-2.0, label='f')\n",
    "L = d*f; L.label = 'L'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual backward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Manual backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L = L\n",
    "\n",
    "dL/dL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.grad = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "L &= d \\cdot f \\\\\n",
    "\\frac{dL}{dd} &= f \\\\\n",
    "\\frac{f(x+h) + f(a)}{h} &= \\frac{(d+h) \\cdot f - d \\cdot f}{h} \\\\\n",
    "&= \\frac{d \\cdot f + h \\cdot f - d \\cdot f}{h} \\\\\n",
    "&= \\frac{h \\cdot f}{h} \\\\\n",
    "&= f\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.grad = d.data\n",
    "d.grad = f.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{dL}{dc} &= ? \\\\\n",
    "\\frac{dL}{de} &= ? \\\\\n",
    "\\frac{dd}{dc} &= ? \\\\\n",
    "d &= e + c \\\\\n",
    "\\frac{dd}{dc} &= 1 \\\\\n",
    "\\frac{dd}{de} &= 1 \\\\\n",
    "\\frac{dL}{dc} &= \\frac{dL}{dd} \\cdot \\frac{dd}{dc}\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.grad = d.grad  * 1\n",
    "c.grad = d.grad  * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plus nodes works as a routing for the gradient at the backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{dL}{da} &= ? \\\\\n",
    "\\frac{dL}{db} &= ? \\\\\n",
    "\n",
    "e &= a \\cdot b \\\\\n",
    "\\frac{de}{da} &= b \\\\\n",
    "\\frac{de}{db} &= a \\\\\n",
    "\\frac{dL}{da} &= \\frac{dL}{dd} \\cdot \\frac{dd}{de} \\cdot \\frac{de}{da} = f \\cdot 1 \\cdot b \\\\\n",
    "\\frac{dL}{db} &= \\frac{dL}{dd} \\cdot \\frac{dd}{de} \\cdot \\frac{de}{db} = f \\cdot 1 \\cdot a\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.grad = e.grad  * 1 * b.data\n",
    "b.grad = e.grad  * 1 * a.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.data += a.grad * 0.01\n",
    "b.data += b.grad * 0.01\n",
    "c.data += c.grad * 0.01\n",
    "f.data += f.grad * 0.01\n",
    "\n",
    "e = a*b\n",
    "d = e + c\n",
    "L = d*f\n",
    "\n",
    "print(L.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lol():\n",
    "\n",
    "    h = 0.001\n",
    "\n",
    "    a = Value(2.0, label='a')\n",
    "    b = Value(-3.0, label='b')\n",
    "    c = Value(10.0, label='c')\n",
    "    e = a*b; e.label = 'e'\n",
    "    d = e + c; d.label = 'd'\n",
    "    f = Value(-2.0, label='f')\n",
    "    L = d*f; L.label = 'L'\n",
    "    L1 = L.data\n",
    "\n",
    "    a = Value(2.0, label='a')\n",
    "    b = Value(-3.0, label='b')\n",
    "    c = Value(10.0+h, label='c')\n",
    "    e = a*b; e.label = 'e'\n",
    "    d = e + c; d.label = 'd'\n",
    "    # d.data += h\n",
    "    f = Value(-2.0, label='f')\n",
    "    L = d*f; L.label = 'L'\n",
    "    L2 = L.data\n",
    "\n",
    "    print('dL/dL', (L2-L1)/h)\n",
    "\n",
    "lol()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperbolic tangent definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xs, np.tanh(xs))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Manual backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize values of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs x1, x2\n",
    "x1 = Value(2.0, label='x1')\n",
    "x2 = Value(0.0, label='x2')\n",
    "\n",
    "# weights w1, w2\n",
    "w1 = Value(-3.0, label='w1')\n",
    "w2 = Value(1.0, label='w2')\n",
    "\n",
    "# bias b\n",
    "b = Value(6.8813735870195432, label='b')\n",
    "\n",
    "# x1w1 + x2w2 + b\n",
    "x1w1 = x1 * w1\n",
    "x1w1.label = 'x1*w1'\n",
    "\n",
    "x2w2 = x2 * w2\n",
    "x2w2.label = 'x2*w2'\n",
    "\n",
    "x1w1x2w2 = x1w1 + x2w2\n",
    "x1w1x2w2.label = 'x1*w1 + x2*w2'\n",
    "\n",
    "n = x1w1x2w2 + b; n.label = 'n'\n",
    "o = n.tanh(); o.label = 'o'\n",
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.grad = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do / dn\n",
    "\n",
    "o = tanh(n)\n",
    "\n",
    "do = 1 - tanh(n)**2 = 1 o**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.grad = (1 - o.data**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.grad = n.grad * 1\n",
    "x1w1x2w2.grad = n.grad * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1w1.grad = x1w1x2w2.grad * 1\n",
    "x2w2.grad = x1w1x2w2.grad * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x1w1 = x1 * w1\n",
    "\n",
    "x2w2 = x2 * w2\n",
    "\n",
    "dx1w1 / dx1 = x2\n",
    "\n",
    "dx2w2 / dx2 = x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.grad = x1w1.grad * w1.data\n",
    "w1.grad = x1w1.grad * x1.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2.grad = x2w2.grad * w2.data\n",
    "w2.grad = x2w2.grad * x2.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semiautomation of the backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset values of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs x1, x2\n",
    "x1 = Value(2.0, label='x1')\n",
    "x2 = Value(0.0, label='x2')\n",
    "\n",
    "# weights w1, w2\n",
    "w1 = Value(-3.0, label='w1')\n",
    "w2 = Value(1.0, label='w2')\n",
    "\n",
    "# bias b\n",
    "b = Value(6.8813735870195432, label='b')\n",
    "\n",
    "# x1w1 + x2w2 + b\n",
    "x1w1 = x1 * w1\n",
    "x1w1.label = 'x1*w1'\n",
    "\n",
    "x2w2 = x2 * w2\n",
    "x2w2.label = 'x2*w2'\n",
    "\n",
    "x1w1x2w2 = x1w1 + x2w2\n",
    "x1w1x2w2.label = 'x1*w1 + x2*w2'\n",
    "\n",
    "n = x1w1x2w2 + b; n.label = 'n'\n",
    "o = n.tanh(); o.label = 'o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.grad = 1.0\n",
    "o._backward()\n",
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n._backward()\n",
    "b._backward()\n",
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1w1x2w2._backward()\n",
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2w2._backward()\n",
    "x1w1._backward()\n",
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topological graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topo = []\n",
    "visited = set()\n",
    "\n",
    "def build_topo(v):\n",
    "    if v not in visited:\n",
    "        visited.add(v)\n",
    "        for child in v._prev:\n",
    "            build_topo(child)\n",
    "        topo.append(v)\n",
    "\n",
    "build_topo(o)\n",
    "topo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "This code defines a topological sorting function, which is useful when dealing with directed graphs (like computational graphs in deep learning). Let's go step by step:\n",
    "\n",
    "1. **`topo = []`**: \n",
    "   - This is an empty list that will eventually store the vertices of the graph in topological order (a linear ordering of vertices where for every directed edge `u -> v`, `u` comes before `v`).\n",
    "\n",
    "2. **`visited = set()`**: \n",
    "   - `visited` is a set used to keep track of all nodes that have already been processed (visited). This avoids revisiting the same node and potentially falling into infinite loops when dealing with graphs that have cycles.\n",
    "   - The `set()` function creates an empty set. A set is a data structure that stores unique elements and allows fast membership testing. So, when you check `if v not in visited`, it’s an efficient way to see if `v` has been processed before.\n",
    "   \n",
    "   **Why `set()`?**  \n",
    "   - The use of `set()` helps ensure that nodes are only visited once because a set automatically handles duplicates (i.e., it only stores unique elements).\n",
    "   - The method `visited.add(v)` adds the node `v` to the set, ensuring it won't be visited again.\n",
    "\n",
    "3. **`build_topo(v)`**:\n",
    "   - This is a recursive function that processes each vertex `v`.\n",
    "   - It checks whether `v` has already been visited using the `visited` set. If not, it adds `v` to the `visited` set and processes all its children recursively using `for child in v._prev: build_topo(child)`.\n",
    "   - Once all children of `v` are processed, `v` is added to the `topo` list.\n",
    "\n",
    "4. **`build_topo(0)`**:\n",
    "   - This line starts the recursive topological sorting with the vertex `0` (the starting node). It assumes that `v._prev` contains a list of preceding nodes connected to `v`.\n",
    "\n",
    "5. **`topo`**:\n",
    "   - After the recursion completes, `topo` will contain the nodes in topologically sorted order.\n",
    "\n",
    "### Example Use Case:\n",
    "This pattern is often used in dependency resolution, where you want to process nodes in a directed acyclic graph (DAG) in such a way that each node is processed after all its dependencies have been processed. For instance, in deep learning, it might be used to ensure that you compute gradients in the correct order in the backward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automation of the backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reseting gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs x1, x2\n",
    "x1 = Value(2.0, label='x1')\n",
    "x2 = Value(0.0, label='x2')\n",
    "\n",
    "# weights w1, w2\n",
    "w1 = Value(-3.0, label='w1')\n",
    "w2 = Value(1.0, label='w2')\n",
    "\n",
    "# bias b\n",
    "b = Value(6.8813735870195432, label='b')\n",
    "\n",
    "# x1w1 + x2w2 + b\n",
    "x1w1 = x1 * w1\n",
    "x1w1.label = 'x1*w1'\n",
    "\n",
    "x2w2 = x2 * w2\n",
    "x2w2.label = 'x2*w2'\n",
    "\n",
    "x1w1x2w2 = x1w1 + x2w2\n",
    "x1w1x2w2.label = 'x1*w1 + x2*w2'\n",
    "\n",
    "n = x1w1x2w2 + b\n",
    "n.label = 'n'\n",
    "o = n.tanh(); o.label = 'o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o._prev, n._prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.backward()\n",
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New topologies - Autonomous Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs x1, x2\n",
    "x1 = Value(2.0, label='x1')\n",
    "x2 = Value(0.0, label='x2')\n",
    "\n",
    "# weights w1, w2\n",
    "w1 = Value(-3.0, label='w1')\n",
    "w2 = Value(1.0, label='w2')\n",
    "\n",
    "# bias b\n",
    "b = Value(6.8813735870195432, label='b')\n",
    "\n",
    "# x1w1 + x2w2 + b\n",
    "x1w1 = x1 * w1\n",
    "x1w1.label = 'x1*w1'\n",
    "\n",
    "x2w2 = x2 * w2\n",
    "x2w2.label = 'x2*w2'\n",
    "\n",
    "x1w1x2w2 = x1w1 + x2w2\n",
    "x1w1x2w2.label = 'x1*w1 + x2*w2'\n",
    "\n",
    "n = x1w1x2w2 + b\n",
    "n.label = 'n'\n",
    "o = n.tanh(); o.label = 'o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.backward()\n",
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Value(2.0, label='a')\n",
    "b = a + a ; b.label = 'b'\n",
    "b.backward()\n",
    "draw_dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Value(-2.0, label='a')\n",
    "b = Value(3.0, label='b')\n",
    "\n",
    "d = a * b\n",
    "d.label = 'd'\n",
    "e = a + b\n",
    "e.label = 'e'\n",
    "f = d * e\n",
    "f.label = 'f'\n",
    "\n",
    "f.backward()\n",
    "draw_dot(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Value(1.0, label='z')\n",
    "tanh_z = z.tanh()  # Call the tanh method of the Value class\n",
    "tanh_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input of the network\n",
    "x1 = torch.Tensor([2.0]).double()           ; x1.requires_grad = True\n",
    "x2 = torch.Tensor([0.0]).double()           ; x2.requires_grad = True\n",
    "w1 = torch.Tensor([-3.0]).double()          ; w1.requires_grad = True\n",
    "w2 = torch.Tensor([1.0]).double()           ; w2.requires_grad = True\n",
    "b  = torch.Tensor([6.8813735870195432]).double() ; b.requires_grad = True\n",
    "\n",
    "# Forward pass\n",
    "n = x1*w1 + x2*w2 + b\n",
    "# Activation function\n",
    "o = torch.tanh(n)\n",
    "\n",
    "print(o.data.item())\n",
    "o.backward()\n",
    "\n",
    "print('----')\n",
    "print('x2', x2.grad.item())\n",
    "print('w2', w2.grad.item())\n",
    "print('x1', x1.grad.item())\n",
    "print('w1', w1.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [2.0, 3.0, -1]\n",
    "n = Neuron(len(x))\n",
    "n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = Layer(len(x), 3)\n",
    "layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = MLP(len(x), [4,4,1])\n",
    "n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(n(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0],\n",
    "]\n",
    "\n",
    "ys = [1.0, -1.0, -1.0, 1.0]  # desired targets\n",
    "y_pred = [n(x) for x in xs]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = sum([(yout - ygt)**2 for ygt, yout in zip(ys, y_pred)])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
